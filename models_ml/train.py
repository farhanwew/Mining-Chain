# -*- coding: utf-8 -*-
"""Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ma4NKZilbedxSSbwrU9Sw6APwsnMOB7d
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os

import requests, os, json
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.utils import resample
from sklearn.model_selection import learning_curve

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder

weather = pd.read_csv("data/Dataset/Raw_Data/weather_dataset.csv")
road = pd.read_csv("data/Dataset/Raw_Data/road_condition_dataset.csv")
equipment = pd.read_csv("data/Dataset/Raw_Data/heavy_equipment_dataset.csv")
production = pd.read_csv("data/Dataset/Raw_Data/production_dataset.csv")
logistics = pd.read_csv("data/Dataset/Raw_Data/logistics_dataset.csv")
vessel = pd.read_csv("data/Dataset/Raw_Data/vessel_schedule_dataset.csv")

"""### fungsi evaluasi model dan visulisasi distribusi kelas"""

def plot_class_distribution(df, column, title=None, palette='Set2'):

    # Jika tidak ada judul, buat otomatis
    if title is None:
        title = f"Distribusi Kolom: {column}"

    # Visualisasi countplot
    plt.figure(figsize=(6,4))
    sns.countplot(data=df, x=column, palette=palette)
    plt.title(title)
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.xticks(rotation=15)
    plt.tight_layout()
    plt.show()

    # Tampilkan jumlah per kelas di terminal
    print("Jumlah data per kelas:")
    print(df[column].value_counts())

def check_overfitting_pipeline(model_pipeline, X_train, X_test, y_train, y_test):
    """
    Mengecek potensi overfitting atau underfitting pada model pipeline.

    Parameter:
    - model_pipeline : Pipeline (contoh: model_equipment)
    - X_train, X_test, y_train, y_test : Data hasil split
    """

    # --- 1Ô∏è‚É£ Prediksi Training & Testing ---
    y_pred_train = model_pipeline.predict(X_train)
    y_pred_test = model_pipeline.predict(X_test)

    # --- 2Ô∏è‚É£ Hitung Akurasi ---
    train_acc = accuracy_score(y_train, y_pred_train)
    test_acc = accuracy_score(y_test, y_pred_test)

    # --- 3Ô∏è‚É£ Tampilkan Evaluasi Dasar ---
    print("="*65)
    print("üîç HASIL EVALUASI MODEL PIPELINE")
    print("="*65)
    print(f"Akurasi Training : {train_acc:.4f}")
    print(f"Akurasi Testing  : {test_acc:.4f}")
    print("\nüìä Laporan Klasifikasi (Testing):")
    print(classification_report(y_test, y_pred_test))
    print("="*65)

    # --- 4Ô∏è‚É£ Analisis Overfitting/Underfitting ---
    gap = train_acc - test_acc
    if gap > 0.1:
        print("‚ö†Ô∏è  Model kemungkinan **Overfitting** (Training jauh lebih tinggi dari Testing)")
    elif gap < -0.05:
        print("‚ùó Model kemungkinan **Underfitting** (Testing lebih tinggi dari Training ‚Äî tidak umum)")
    else:
        print("‚úÖ Model memiliki **Generalization** yang baik")
    print("="*65)

    # --- 5Ô∏è‚É£ Visualisasi Akurasi Train vs Test ---
    plt.figure(figsize=(6,4))
    plt.bar(['Train', 'Test'], [train_acc, test_acc], color=['#4CAF50', '#2196F3'])
    plt.title('Perbandingan Akurasi Train vs Test')
    plt.ylabel('Accuracy')
    plt.ylim(0, 1)
    plt.show()

    # --- 6Ô∏è‚É£ Learning Curve (untuk analisis lebih lanjut) ---
    X_all = pd.concat([X_train, X_test])
    y_all = pd.concat([y_train, y_test])

    train_sizes, train_scores, test_scores = learning_curve(
        model_pipeline,
        X_all,
        y_all,
        cv=5,
        train_sizes=np.linspace(0.1, 1.0, 5),
        scoring='accuracy',
        n_jobs=-1
    )

    # --- 7Ô∏è‚É£ Visualisasi Learning Curve ---
    plt.figure(figsize=(8,5))
    plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', label='Train Accuracy')
    plt.plot(train_sizes, np.mean(test_scores, axis=1), 'o-', label='Test Accuracy')
    plt.title('Learning Curve (Pipeline Model)')
    plt.xlabel('Jumlah Data Training')
    plt.ylabel('Akurasi')
    plt.legend()
    plt.grid(True)
    plt.show()

"""### Preprocessing Weather + train Model"""

weather.info()

weather.shape

plot_class_distribution(weather, 'Weather_Risk_Level', title='Distribusi Weather Sebelum Resampling')

safe = weather[weather['Weather_Risk_Level'] == 'Safe']
caution = weather[weather['Weather_Risk_Level'] == 'Caution']
high = weather[weather['Weather_Risk_Level'] == 'High Risk']

n_target = max(len(safe), len(caution), len(high))

# Oversampling manual agar semua sama
safe_bal = resample(safe, replace=True, n_samples=n_target, random_state=42)
caution_bal = resample(caution, replace=True, n_samples=n_target, random_state=42)
high_bal = resample(high, replace=True, n_samples=n_target, random_state=42)


# Gabungkan kembali
weather= pd.concat([safe_bal, caution_bal, high_bal])
print(weather.shape)
# Cek hasil
print(weather['Weather_Risk_Level'].value_counts())

plot_class_distribution(weather, 'Weather_Risk_Level', title='Distribusi Weather sesudah Resampling')

X = weather.drop(columns=['Date', 'Weather_Risk_Level'])
y = weather['Weather_Risk_Level']

Features_weather = X.columns.tolist()
print(Features_weather)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=['float64', 'int64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

model_Weather = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

model_Weather.fit(X_train, y_train)

"""## Evaluasi Wheater"""

check_overfitting_pipeline(model_Weather, X_train, X_test, y_train, y_test)

"""## Preprocessing Road + Train Model"""

road.head()

plot_class_distribution(road, 'Road_Condition_Status', title='Distribusi Road Sebelum Resampling')

road.dropna(inplace=True)
road.drop_duplicates(inplace=True)

road.isnull().sum()

road.duplicated().sum()

operational = road[road['Road_Condition_Status'] == 'Operational']
sev_dam = road[road['Road_Condition_Status'] == 'Severely Damaged']
Closed = road[road['Road_Condition_Status'] == 'Closed']

n_target = max(len(operational), len(sev_dam), len(Closed))

# Oversampling manual agar semua sama
operational_bal = resample(operational, replace=True, n_samples=n_target, random_state=42)
sev_dam_bal = resample(sev_dam, replace=True, n_samples=n_target, random_state=42)
Closed_bal = resample(Closed, replace=True, n_samples=n_target, random_state=42)


# Gabungkan kembali
road = pd.concat([operational_bal, sev_dam_bal,Closed_bal])
print(road.shape)
# Cek hasil
print(road['Road_Condition_Status'].value_counts())

plot_class_distribution(road, 'Road_Condition_Status', title='Distribusi road sesudah Resampling')

X = road.drop(columns=['Date', 'Road_Condition_Status'])
y = road['Road_Condition_Status']

Features_road = X.columns.tolist()
print(Features_road)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=['float64', 'int64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

model_road = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

model_road.fit(X_train, y_train)

"""## Evaluasi Model Road"""

check_overfitting_pipeline(model_road, X_train, X_test, y_train, y_test)

"""### Preprocessing Heavy Equipment + Train Model"""

equipment.head()

equipment.drop(columns=['Timestamp','Machine_ID','Operator_ID'], inplace=True)

plot_class_distribution(equipment, 'Machine_Failure', title='Distribusi Awal Machine_Failure Sebelum Resampling')

equipment.dropna(inplace=True)
equipment.drop_duplicates(inplace=True)

equipment.isnull().sum()

equipment.duplicated().sum()

Yes = equipment[equipment['Machine_Failure'] == 1]
No = equipment[equipment['Machine_Failure'] == 0]


n_target = max(len(Yes), len(No))

# Oversampling manual agar semua sama
Yes_bal = resample(Yes, replace=True, n_samples=n_target, random_state=42)
No_bal = resample(No, replace=True, n_samples=n_target, random_state=42)



# Gabungkan kembali
equipment = pd.concat([Yes_bal, No_bal])
print(equipment.shape)
# Cek hasil
print(equipment['Machine_Failure'].value_counts())

plot_class_distribution(equipment, 'Machine_Failure', title='Distribusi Awal Machine_Failure sesudah Resampling')

equipment.head()

X = equipment.drop(columns=['Machine_Failure'])
y = equipment['Machine_Failure']

Features_equipment = X.columns.tolist()
print(Features_equipment)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=['float64', 'int64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

model_equipment = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

model_equipment.fit(X_train, y_train)

"""## Evaluasi Model equipment"""

check_overfitting_pipeline(model_equipment, X_train, X_test, y_train, y_test)

"""## Preprocessing Vessel + Train Model"""

vessel.head()

vessel.drop(columns=['Record_Timestamp','Vessel_ID','Route_Code','Actual_Arrival_Time'],inplace=True)

vessel['Departure_Time'] = pd.to_datetime(vessel['Departure_Time'])
vessel['Planned_Arrival_Time'] = pd.to_datetime(vessel['Planned_Arrival_Time'])


# Jam keberangkatan (0‚Äì23)
vessel['Departure_Hour'] = vessel['Departure_Time'].dt.hour

# Hari keberangkatan (Senin=0, Minggu=6)
vessel['Departure_Weekday'] = vessel['Departure_Time'].dt.dayofweek

# Bulan keberangkatan (1‚Äì12)
vessel['Departure_Month'] = vessel['Departure_Time'].dt.month

# Durasi perjalanan terencana (dalam jam)
vessel['Planned_Duration_hours'] = (
    (vessel['Planned_Arrival_Time'] - vessel['Departure_Time']).dt.total_seconds() / 3600
)

# Hapus kolom waktu mentah setelah diturunkan
vessel = vessel.drop(['Departure_Time', 'Planned_Arrival_Time'], axis=1)

plot_class_distribution(vessel, 'Delay_Risk', title='Distribusi Awal Delay_Risk Sebelum Resampling')

on_time = vessel[vessel['Delay_Risk'] == 'On Time']
late = vessel[vessel['Delay_Risk'] == 'Late']
weather_delay = vessel[vessel['Delay_Risk'] == 'Weather Delay']

n_target = max(len(on_time), len(late), len(weather_delay))

# Oversampling manual agar semua sama
ontime_bal = resample(on_time, replace=True, n_samples=n_target, random_state=42)
late_bal = resample(late, replace=True, n_samples=n_target, random_state=42)
weatherdelay_bal = resample(weather_delay, replace=True, n_samples=n_target, random_state=42)


# Gabungkan kembali
vessel= pd.concat([ontime_bal, late_bal, weatherdelay_bal])
print(vessel.shape)
# Cek hasil
print(vessel['Delay_Risk'].value_counts())

plot_class_distribution(vessel, 'Delay_Risk', title='Distribusi Awal Delay_Risk')

X = vessel.drop(columns=['Delay_Risk'])
y = vessel['Delay_Risk']

Features_vessel = X.columns.tolist()
print(Features_vessel)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=['float64', 'int64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

model_vessel = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

model_vessel.fit(X_train, y_train)

"""## evaluasi model vessel"""

check_overfitting_pipeline(model_vessel, X_train, X_test, y_train, y_test)

"""## Preprocessing Logistics + train model"""

logistics.head()

logistics.info()

logistics.drop(columns=['Record_Timestamp', 'Logistics_ID', 'Vessel_ID', 'Machine_ID', 'Driver_ID'], inplace=True)

plot_class_distribution(logistics, 'Delivery_Risk_Level', title='Distribusi Sebelum Delivery_Risk_Level sebelum Resampling')

high = logistics[logistics['Delivery_Risk_Level'] == 'High']
medium = logistics[logistics['Delivery_Risk_Level'] == 'Medium']
Low = logistics[logistics['Delivery_Risk_Level'] == 'Low']

n_target = max(len(high), len(medium), len(Low))

# Oversampling manual agar semua sama
high_bal = resample(high, replace=True, n_samples=n_target, random_state=42)
medium_bal = resample(medium, replace=True, n_samples=n_target, random_state=42)
Low_bal = resample(Low, replace=True, n_samples=n_target, random_state=42)


# Gabungkan kembali
logistics = pd.concat([high_bal, medium_bal,Low_bal])
print(logistics.shape)
# Cek hasil
print(logistics['Delivery_Risk_Level'].value_counts())

plot_class_distribution(logistics, 'Delivery_Risk_Level', title='Distribusi Sesudah Delivery_Risk_Level seusdah Resampling')

X = logistics.drop(columns=['Delivery_Risk_Level'])
y = logistics['Delivery_Risk_Level']

Features_logistics = X.columns.tolist()
print(Features_logistics)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=['float64', 'int64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

model_logistic = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

model_logistic.fit(X_train, y_train)

check_overfitting_pipeline(model_logistic, X_train, X_test, y_train, y_test)

"""### preprocessing Production + Train Model"""

production.head()

"""dari dataset di atas dapat dilakukan
- Klasifikasi Risiko Produksi
- Production Risk Level Classification
- Prediksi Produksi (Production_Tons)
"""

plot_class_distribution(production, 'Production_Risk_Level', title='Distribusi Production_Risk_Level sebelum Resampling')

high = production[production['Production_Risk_Level'] == 'High']
medium = production[production['Production_Risk_Level'] == 'Medium']
low = production[production['Production_Risk_Level'] == 'Low']

n_target = max(len(high), len(medium), len(low))

high_bal = resample(high, replace=True, n_samples=n_target, random_state=42)
medium_bal = resample(medium, replace=True, n_samples=n_target, random_state=42)
low_bal = resample(low, replace=True, n_samples=n_target, random_state=42)

production = pd.concat([high_bal, medium_bal, low_bal])

plot_class_distribution(production, 'Production_Risk_Level', title='Distribusi Production_Risk_Level sesudah reasampling')

X1 = production.drop(columns=['Production_Risk_Level'])
y1 = production['Production_Risk_Level']

num_cols1 = X1.select_dtypes(include=['int64','float64']).columns
cat_cols1 = X1.select_dtypes(include=['object']).columns

preprocessor1 = ColumnTransformer([
    ('num', StandardScaler(), num_cols1),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols1)
])

model1_production = Pipeline([
    ('preprocessor', preprocessor1),
    ('classifier', RandomForestClassifier(random_state=42))
])

Features_production = X1.columns.tolist()
print(Features_production)

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)

model1_production.fit(X1_train, y1_train)

check_overfitting_pipeline(model1_production, X1_train, X1_test, y1_train, y1_test)

"""### simpan model"""

import os
import joblib
import pandas as pd

# === 1Ô∏è‚É£ Buat folder penyimpanan model ===
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# === 2Ô∏è‚É£ Daftar model dan atribut masing-masing ===
models_to_save = {
    'model_weather.pkl': {
        "model": model_Weather,
        "features": Features_weather
    },
    'model_road.pkl': {
        "model": model_road,
        "features": Features_road
    },
    'model_equipment.pkl': {
        "model": model_equipment,
        "features": Features_equipment
    },
    'model_vessel.pkl': {
        "model": model_vessel,
        "features": Features_vessel
    },
    'model_logistics.pkl': {
        "model": model_logistic,
        "features": Features_logistics
    },
    'model_production.pkl': {
        "model": model1_production,
        "features": Features_production  # X1 = data training production
    }
}

# === 3Ô∏è‚É£ Simpan setiap model + fitur ===
for filename, content in models_to_save.items():
    model = content["model"]
    features = content["features"]

    file_path = os.path.join(MODEL_DIR, filename)

    model_package = {
        "model": model,
        "feature_order": features,
        "model_name": filename.split(".")[0],
    }

    joblib.dump(model_package, file_path)
    print(f"‚úÖ Model '{filename}' berhasil disimpan di: {file_path}")
    print(f"   Jumlah fitur: {len(features)} kolom")

